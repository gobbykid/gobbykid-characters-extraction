{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/tommasobattisti/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/tommasobattisti/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import syntok.segmenter as segmenter\n",
    "import os\n",
    "import re\n",
    "import gender_guesser.detector as ggd\n",
    "import gender_detector as g_d\n",
    "import nltk as nltk\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import difflib\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "nlp.max_length = 2000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Corpus/female-writers/1872_de-la-ramee-a-dog-of-flanders.txt',\n",
       " 'Corpus/female-writers/1857_browne-grannys-wonderful-chair.txt',\n",
       " 'Corpus/female-writers/1877_molesworth-the-cuckoo-clock.txt',\n",
       " 'Corpus/female-writers/1877_sewell-black-beauty.txt',\n",
       " 'Corpus/female-writers/1902_potter-the-tale-of-peter-rabbit.txt',\n",
       " 'Corpus/female-writers/1899_nesbit-the-story-of-the-treasure-seekers.txt',\n",
       " 'Corpus/female-writers/1869_ewing-mrs-overtheways-remembrances.txt',\n",
       " 'Corpus/female-writers/1886_hodgson-burnett-little-lord-fauntleroy.txt',\n",
       " 'Corpus/male-writers/1888_wilde-the-happy-prince-and-other-tales.txt',\n",
       " 'Corpus/male-writers/1871_macdonald-at-the-back-of-the-north-wind.txt',\n",
       " 'Corpus/male-writers/1894_kipling-the-jungle-book.txt',\n",
       " 'Corpus/male-writers/1869_dickens-david-copperfield.txt',\n",
       " 'Corpus/male-writers/1865_carroll-alices-adventures-in-wonderland.txt',\n",
       " 'Corpus/male-writers/1857_hughes-tom-browns-school-days.txt',\n",
       " 'Corpus/male-writers/1883_stevenson-treasure-island.txt',\n",
       " 'Corpus/male-writers/1876_twain-the-adventures-of-tom-sawyer.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_paths = [\"Corpus/female-writers/\", \"Corpus/male-writers/\"]\n",
    "file_paths = []\n",
    "\n",
    "for path in directory_paths:\n",
    "    for root, directories, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            # Join the two strings in order to form the full filepath.\n",
    "            filepath = os.path.join(root, filename)\n",
    "            file_paths.append(filepath)\n",
    "\n",
    "\n",
    "\n",
    "file_paths_1880 = []\n",
    "for root, directories, files in os.walk(\"Corpus1880/\"):\n",
    "    for filename in files:\n",
    "        # Join the two strings in order to form the full filepath.\n",
    "        filepath = os.path.join(root, filename)\n",
    "        file_paths_1880.append(filepath)\n",
    "\n",
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_characters(book, book_path):\n",
    "    names_list = []\n",
    "\n",
    "    #this following commented part was useful to manage only the specific case of \"The story of the treasure seekers\" by Nesbit\n",
    "    \"\"\" if re.findall(\"nesbit-the-story-of-the-treasure-seekers\\.txt$\", book_path):\n",
    "        book = re.sub('([A-Z]{2,})',lambda low: low.group(1).lower() , book)\n",
    "        book = re.sub('H\\.\\sO\\.', 'Horace Octavius', book)\n",
    "        book = re.sub('Horace\\sOctavius(\\n)+', 'Horace Octavius.', book)  \n",
    "        book = re.sub('Horace\\sOctavius\\s([A-Z])', lambda pat: \"Horace Octavius \" + pat.group(1).lower(), book)\n",
    "        book = re.sub('([A-Z]\\w+)\\sHorace\\sOctavius', lambda pat: pat.group(1).lower() + \" Horace Octavius\", book)\n",
    "        book = re.sub('G\\.\\sB\\.', 'Generous Benefactor', book) \"\"\"\n",
    "\n",
    "    book = re.sub('‘([A-Z])', lambda pat: \"‘\" + pat.group(1).lower(), book)\n",
    "    book = re.sub('\\n', ' ', book)\n",
    "    book = re.sub(\"’[^st]\", ' ', book)\n",
    "    book = re.sub(\"‘\", \" \", book)\n",
    "    book = re.sub('--', ' ', book)\n",
    "    book = re.sub('-', ' ', book)\n",
    "    book = re.sub('_', ' ', book)\n",
    "    book = re.sub('- -', ' ', book)\n",
    "    book = re.sub('\\*', ' ', book)\n",
    "    book = re.sub('\\s+', ' ', book)\n",
    "\n",
    "    \n",
    "    nltk_name_dict, sentences_num = get_charaters_nltk(book)\n",
    "    spacy_name_dict = get_characters_spacy(book)\n",
    "\n",
    "    nltk_name_dict = rebalance_name_dict(nltk_name_dict, sentences_num)\n",
    "    spacy_name_dict = rebalance_name_dict(spacy_name_dict, sentences_num)\n",
    "\n",
    "    print(\"nltk\\n\", nltk_name_dict)\n",
    "    print(\"spacy\\n\", spacy_name_dict)\n",
    "\n",
    "    for key in spacy_name_dict:\n",
    "        if sentences_num >= 17000:\n",
    "            if spacy_name_dict[key] >= 35 or key in nltk_name_dict and nltk_name_dict[key] >= 20 and key not in names_list:\n",
    "                names_list.append(key)\n",
    "        else:\n",
    "            if spacy_name_dict[key] >= 7 or key in nltk_name_dict and nltk_name_dict[key] >= 2 and key not in names_list:\n",
    "                names_list.append(key)\n",
    "    \n",
    "    for key in nltk_name_dict:\n",
    "        if sentences_num >= 17000:\n",
    "            if key not in names_list and nltk_name_dict[key] >= 35:\n",
    "                names_list.append(key)\n",
    "        else:\n",
    "            if key not in names_list and nltk_name_dict[key] >= 7:\n",
    "                names_list.append(key)\n",
    "    \n",
    "    return check_name_strings(names_list)\n",
    "\n",
    "\n",
    "def check_name_strings(names_list):\n",
    "    regex_dict = {\".+!\":(\"!\", \"\"), \"[Tt]he\\s.+\":(\"[Tt]he\\s\", \"\"), \"[oO]\\s.+\": (\"[Oo]\\s\", \"\"), \".+['’]s\": (\"['’]s\", \"\"), \".+\\s['’]s\": (\"\\s['’]s\", \"\"), \"[Pp]rince\\s.+\": (\"[Pp]rince\\s\", \"\"), \"[Pp]rincess\\s.+\": (\"[Pp]rincess\\s\", \"\"), \"[Kk]ing\\s.+\": (\"[Kk]ing\\s\", \"\"), \"[Qq]ueen\\s.+\": (\"[Qq]ueen\\s\", \"\"), \"[Dd]ame\\s.+\": (\"[Dd]ame\\s\", \"\"), \"[Ll]ady\\s.+\": (\"[Ll]ady\\s\", \"\"), \".+['’,.]\": (\"['’,.]\", \"\")}\n",
    "    name_set = set()\n",
    "    not_names = [\"sir\", \"lord\", \"lady\", \"king\", \"queen\", \"prince\", \"princess\", \"dame\", \"miss\", \"mister\", \"mr\", \"cap\", \"i\", \"me\", \"you\", \"aunt\", \"mother\", \"father\", \"uncle\"]\n",
    "    for name in names_list:\n",
    "        s_name = name.strip()\n",
    "        if s_name.lower() not in not_names and not re.match(\"[Pp]art\\s.+|[Cc]hapter\\s.+\", s_name):\n",
    "            for regex in regex_dict:\n",
    "                if re.match(regex, name):\n",
    "                    s_name = re.sub(regex_dict[regex][0], regex_dict[regex][1], s_name)\n",
    "            if s_name[0].isupper() and not (re.match(\"Christmas\", s_name) or re.match(\".+\\sChristmas\", s_name) or re.match(\".+\\s[Ii]sland\", s_name) or re.match(\".+\\s[Ll]ake\", s_name)):\n",
    "                name_set.add(s_name.strip())\n",
    "    return list(name_set)\n",
    "\n",
    "\n",
    "\n",
    "def rebalance_name_dict(name_dict, sentences_number):\n",
    "    names_list = list(name_dict.keys())\n",
    "    while len(names_list) > 0:\n",
    "        last_nl = names_list.pop()\n",
    "        for name in names_list:\n",
    "            similarity = difflib.SequenceMatcher(None, last_nl, name)\n",
    "            if similarity.ratio() >= 0.7:\n",
    "                if sentences_number < 1000:\n",
    "                    name_dict[last_nl] += 5 \n",
    "                    name_dict[name] += 5\n",
    "                else:\n",
    "                    x = name_dict[last_nl]\n",
    "                    y = name_dict[name]\n",
    "                    name_dict[last_nl] += y\n",
    "                    name_dict[name] += x\n",
    "    return name_dict\n",
    "\n",
    "\n",
    "\n",
    "def get_charaters_nltk(book):\n",
    "    nltk_name_dict = {}\n",
    "    tokenized_sentences = nltk.sent_tokenize(book)\n",
    "    for sent in tokenized_sentences:\n",
    "        chunked = nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent)))   \n",
    "        for item in chunked:\n",
    "            if type(item) == nltk.Tree and item.label() == \"PERSON\":\n",
    "                if \" \".join([token for token, pos in item.leaves()]) not in nltk_name_dict:\n",
    "                    nltk_name_dict[\" \".join([token for token, pos in item.leaves()])] = 0\n",
    "                nltk_name_dict[\" \".join([token for token, pos in item.leaves()])] += 1\n",
    "\n",
    "    return nltk_name_dict, len(tokenized_sentences)\n",
    "\n",
    "\n",
    "\n",
    "def get_characters_spacy(book):\n",
    "    spacy_name_dict = {}\n",
    "    doc = nlp(book)\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            if ent.text not in spacy_name_dict:\n",
    "                spacy_name_dict[ent.text] = 0\n",
    "            spacy_name_dict[ent.text] += 1\n",
    "    \n",
    "    return spacy_name_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ncl = get_characters(open(file_paths[5]).read(), file_paths[5])\n",
    "print(\"__________________________________________________________\\n\",ncl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_guesser = ggd.Detector()\n",
    "\n",
    "ns_splitted = []\n",
    "\n",
    "lista_gg = []\n",
    "\n",
    "for n in ncl:\n",
    "    if re.match(\".+\\s.+\", n):\n",
    "        split = n.split(\" \")\n",
    "        ns_splitted.append(split)\n",
    "    else:\n",
    "        ns_splitted.append([n])\n",
    "\n",
    "for ns in ns_splitted:\n",
    "    for nns in ns:\n",
    "        lista_gg.append((ns, nns, gender_guesser.get_gender(nns)))\n",
    "\n",
    "print(\"_______GG_________\",lista_gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ns_splitted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/tommasobattisti/Desktop/Materiale progetto digital text/DigitalTextProject/CharactersGenderRecognition.ipynb Cella 5\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tommasobattisti/Desktop/Materiale%20progetto%20digital%20text/DigitalTextProject/CharactersGenderRecognition.ipynb#ch0000004?line=1'>2</a>\u001b[0m detector \u001b[39m=\u001b[39m gd\u001b[39m.\u001b[39mGenderDetector(\u001b[39m'\u001b[39m\u001b[39muk\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tommasobattisti/Desktop/Materiale%20progetto%20digital%20text/DigitalTextProject/CharactersGenderRecognition.ipynb#ch0000004?line=4'>5</a>\u001b[0m lista_gd \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tommasobattisti/Desktop/Materiale%20progetto%20digital%20text/DigitalTextProject/CharactersGenderRecognition.ipynb#ch0000004?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m ns \u001b[39min\u001b[39;00m ns_splitted:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tommasobattisti/Desktop/Materiale%20progetto%20digital%20text/DigitalTextProject/CharactersGenderRecognition.ipynb#ch0000004?line=8'>9</a>\u001b[0m     \u001b[39mfor\u001b[39;00m nns \u001b[39min\u001b[39;00m ns:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tommasobattisti/Desktop/Materiale%20progetto%20digital%20text/DigitalTextProject/CharactersGenderRecognition.ipynb#ch0000004?line=9'>10</a>\u001b[0m         lista_gd\u001b[39m.\u001b[39mappend((ns, nns, detector\u001b[39m.\u001b[39mguess(nns)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ns_splitted' is not defined"
     ]
    }
   ],
   "source": [
    "from gender_detector import gender_detector as gd\n",
    "detector = gd.GenderDetector('uk')\n",
    "\n",
    "\n",
    "lista_gd = []\n",
    "\n",
    "\n",
    "for ns in ns_splitted:\n",
    "    for nns in ns:\n",
    "        lista_gd.append((ns, nns, detector.guess(nns)))\n",
    "\n",
    "print(\"___________GD_____________\",lista_gd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
